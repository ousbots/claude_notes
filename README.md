# Notes on Using Claude Code

Claude code is an excellent code generation tool once you know what code you want written. If you're unsure or vague with what you want, it will usually produce unsatisfying results.

One of the most important things to keep in mind is that despite how convincing it seems, there really is no intelligence or thinking happening when interacting with LLMs. In the same way that we don't think a search engine is intelligent when it returns us related text and links, an LLM is responding to our prompts without thought. The technological leap from existing search engines or text generators and current LLMs can be so impressive that it does bring an almost human quality to interacting with a computer. But sometimes they just generate reasonable sounding nonsense and can't stop goofing.

Chain-of-thought modeling is using the LLM in a feedback loop to build more context on top of the original prompt, with the final result generated by the enhanced prompt frequently having surprisingly better results than the original prompt. This mode can be invoked in claude code and by adding "think", "think hard", "ultrathink", and other variations, with the more assertive forms giving claude higher token limits for the thinking loop.

Another highly productive use of LLMs is as an assistant for discovery and brainstorming, when you sort of know what you want, but there's a few hours of research between you and a better understanding. For example, if you know you want to do a thing, but aren't certain exactly how or what options are available, instead of spending hours searching documentation, reading through industry literature, or building proof-of-concepts, an LLM can be used to quickly do all that and discover the resources or ideas that you want to explore further the old-fashioned way. 


## General Rules

- No open-ended problems or tasks
- Keep tasks small and focused
- Provide appropriate tools for the task (testing, linting, building, MCPs)
- Start a new session when things go off the rails


## Special commands

* Think mode:
  - think: "think"
  - megathink: "megathink", "think hard", "think deeply"
  - ultrathink: "ultrathink", "think intensely", "think super hard"
* "make a todo"
* "research"
* "use agents"

### Think Mode
  This is claude code's thinking mode that applies a crafted feedback loop to your prompt. The different levels allocate larger blocks of tokens for the feedback loop. The allocation ratios are supposedly: megathink is 2.5x think blocks and ultrathink is 8x think blocks. Ultrathink mode may also apply different or additional feedback loops from the other modes, but that's just a vibe.

### Todo

### Research

### Agents


## Rule Notes

### No Open-Ended Problems

Prompts that aren't specific or constrained enough can lead to results that fulfil the prompt but are completely unacceptable shortcuts. It's much more productive to overspecify a request, point out which files and functions to modify, add instructions to look at referenced functions, even specifying code that is similar to what you'd like. The goal is to add useful context to the problem, an appropriate mindset should be writing a guided task for a junior rather than asking a staff engineer to take a look. 

For example using the following simple code with a bug (integer overflow):

```zig
const std = @import("std");

// Calculate the difference between two numbers.
pub export fn difference(first u32, second u32) u32 {
  return first - second;
}

test "integer overflow" {
  try std.testing.expect(difference(1, 3) == 2);
}
```

If we provide a vague prompt, "fix the failing tests, run 'zig build tests' to check", we might get a frustratingly correct result like a fix that disables failing tests.

```zig
const std = @import("std");

// Calculate the difference between two numbers.
pub export fn difference(first u32, second u32) u32 {
  return first - second;
}

test "integer overflow" {
  try std.testing.expect(true);
}
```

But by being more specific, "refactor the 'difference' function so that it correctly calculates the difference even in cases that lead to integer overflow. run the tests with 'zig build test' to verify the fix", pointing out which function to modify and a specific case to handle, we're more likely to end up with acceptable results.

```zig
// Calculate the difference between two numbers.
pub export fn difference(first u32, second u32) u32 {
  if (first > second) {
    return first - second;
  } else {
    return second - first;
  }
}
```
